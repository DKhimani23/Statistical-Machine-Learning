# Statistical Machine Learning

This repository contains my final coursework submission for the **Statistical Machine Learning** module as part of the MSc in Data Analytics 

The coursework covers mathematical derivations, MLE estimation, Bayesian inference, model fitting, curve smoothing, PCA, clustering, and multinomial logistic regression.

---

## Summary of Contents

### Question 1: Maximum Likelihood Estimation (MLE)
- Derived the MLE of the mean for **normal and Laplace distributions**
- Demonstrated that the sample mean (Normal) and median (Laplace) are the MLEs

### Question 2: Bernoulli Inference
- Frequentist and Bayesian estimation of the parameter \( p \) for Bernoulli trials
- Constructed 95% confidence and credible intervals
- Applied theory to a biological hypothesis (Fisherâ€™s Principle)

### Question 3: Sinusoidal Regression
- Derived the MLE for a parameter in the model \( y = a \cdot \sin(2x) \)
- Linked least squares and MLE under Gaussian noise assumption

### Question 4: Curve Smoothing and Extension
- Used spline smoothing to denoise a hand-drawn curve
- Employed cross-validation to select the optimal smoothness parameter
- Extended the curve using arc-length parameterisation and wrapping

### Question 5: Emotion Recognition via Machine Learning
- Trained a **multinomial logistic regression** classifier on mouth shape data
- Evaluated performance with confusion matrix, precision, recall, F1-score
- Applied **Principal Component Analysis (PCA)** for dimensionality reduction
- Performed **K-Means clustering** and analysed cluster-emotion alignment

---


## Tools & Skills Demonstrated

- Maximum Likelihood Estimation & Bayesian Inference
- Python: `scikit-learn`, `scipy`, `numpy`, `matplotlib`
- Dimensionality Reduction: PCA
- Clustering: K-Means, Elbow Method
- Curve Fitting: UnivariateSpline & Arc Length Parameterisation
- Logistic Regression & Confusion Matrix Analysis

---

